{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caso Práctico: Neurona de McCulloch y Pitts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Aplicando la MPNeuron a un caso práctico real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Conjunto de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta es una copia de los conjuntos de datos de UCI ML Breast Cancer Wisconsin (Diagnóstico). https://goo.gl/U2Uwz2\n",
    "\n",
    "Las características de entrada se calculan a partir de una imagen digitalizada de un aspirado de aguja fina (FNA) de una masa mamaria. Describen las características de los núcleos celulares presentes en la imagen.\n",
    "\n",
    "El plano de separación descrito anteriormente se obtuvo utilizando el método de árbol de múltiples superficies (MSM-T) [K. P. Bennett, \"Construcción de un árbol de decisión mediante programación lineal\". Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society, pp. 97-101, 1992], un método de clasificación que utiliza la programación lineal para construir un árbol de decisión. Los rasgos relevantes se seleccionaron mediante una búsqueda exhaustiva en el espacio de 1-4 rasgos y 1-3 planos de separación.\n",
    "\n",
    "El programa lineal real utilizado para obtener el plano de separación en el espacio tridimensional es el que se describe en: [K. P. Bennett y O. L. Mangasarian: \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34].\n",
    "\n",
    "Esta base de datos también está disponible a través del servidor ftp UW CS:\n",
    "\n",
    "ftp ftp.cs.wisc.edu cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
    "\n",
    "### Referencias\n",
    "\n",
    "* W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on Electronic Imaging: Science and Technology, volume 1905, pages 861-870, San Jose, CA, 1993.\n",
    "* O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and prognosis via linear programming. Operations Research, 43(4), pages 570-577, July-August 1995.\n",
    "* W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) 163-171."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Lectura del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "breast_cancer = load_breast_cancer()\n",
    "\n",
    "X = breast_cancer.data\n",
    "Y = breast_cancer.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR',\n",
       " 'data',\n",
       " 'data_module',\n",
       " 'feature_names',\n",
       " 'filename',\n",
       " 'frame',\n",
       " 'target',\n",
       " 'target_names']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(breast_cancer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "        1.189e-01],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "        8.902e-02],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "        8.758e-02],\n",
       "       ...,\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "        7.820e-02],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "        1.240e-01],\n",
       "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "        7.039e-02]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Visualización del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "0                   0.07871  ...        25.380          17.33   \n",
       "1                   0.05667  ...        24.990          23.41   \n",
       "2                   0.05999  ...        23.570          25.53   \n",
       "3                   0.09744  ...        14.910          26.50   \n",
       "4                   0.05883  ...        22.540          16.67   \n",
       "..                      ...  ...           ...            ...   \n",
       "564                 0.05623  ...        25.450          26.40   \n",
       "565                 0.05533  ...        23.690          38.25   \n",
       "566                 0.05648  ...        18.980          34.12   \n",
       "567                 0.07016  ...        25.740          39.42   \n",
       "568                 0.05884  ...         9.456          30.37   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "0             184.60      2019.0           0.16220            0.66560   \n",
       "1             158.80      1956.0           0.12380            0.18660   \n",
       "2             152.50      1709.0           0.14440            0.42450   \n",
       "3              98.87       567.7           0.20980            0.86630   \n",
       "4             152.20      1575.0           0.13740            0.20500   \n",
       "..               ...         ...               ...                ...   \n",
       "564           166.10      2027.0           0.14100            0.21130   \n",
       "565           155.00      1731.0           0.11660            0.19220   \n",
       "566           126.70      1124.0           0.11390            0.30940   \n",
       "567           184.60      1821.0           0.16500            0.86810   \n",
       "568            59.16       268.6           0.08996            0.06444   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.7119                0.2654          0.4601   \n",
       "1             0.2416                0.1860          0.2750   \n",
       "2             0.4504                0.2430          0.3613   \n",
       "3             0.6869                0.2575          0.6638   \n",
       "4             0.4000                0.1625          0.2364   \n",
       "..               ...                   ...             ...   \n",
       "564           0.4107                0.2216          0.2060   \n",
       "565           0.3215                0.1628          0.2572   \n",
       "566           0.3403                0.1418          0.2218   \n",
       "567           0.9387                0.2650          0.4087   \n",
       "568           0.0000                0.0000          0.2871   \n",
       "\n",
       "     worst fractal dimension  \n",
       "0                    0.11890  \n",
       "1                    0.08902  \n",
       "2                    0.08758  \n",
       "3                    0.17300  \n",
       "4                    0.07678  \n",
       "..                       ...  \n",
       "564                  0.07115  \n",
       "565                  0.06637  \n",
       "566                  0.07820  \n",
       "567                  0.12400  \n",
       "568                  0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(X, columns=breast_cancer.feature_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. División del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de datos de entrenamiento:  426\n",
      "Tamaño del conjunto de datos de pruebas:  143\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, Y, stratify=Y)\n",
    "\n",
    "print(\"Tamaño del conjunto de datos de entrenamiento: \", len(X_train))\n",
    "print(\"Tamaño del conjunto de datos de pruebas: \", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Implementación de una MPNeuron más avanzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class MPNeuron:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.threshold = None\n",
    "        \n",
    "    def model(self, x):\n",
    "        return (sum(x) >= self.threshold)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        Y = []\n",
    "        for x in X:\n",
    "            result = self.model(x)\n",
    "            Y.append(result)\n",
    "        return np.array(Y)\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        accuracy = {}\n",
    "        # Seleccionamos un threshold entre el # de características de entrada\n",
    "        for th in range(X.shape[1] + 1):\n",
    "            self.threshold = th\n",
    "            Y_pred = self.predict(X)\n",
    "            accuracy[th] = accuracy_score(Y_pred, Y)\n",
    "        # Seleccionamos el threshold que mejores resultados proporciona\n",
    "        self.threshold = max(accuracy, key=accuracy.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguimos teniendo un problema debido a que en nuestro conjunto de datos las características de entrada reciben valores continuos, sin embargo, nuestra MPNeuron solo procesa características de entrada con valor binario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1, 1, 1, 0, 0]\n",
      "Categories (2, int64): [0 < 1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Para transformar un valor a binario\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(pd.cut([0.04, 2, 4, 5, 6, 0.02, 0.6], bins=2, labels=[0, 1]))\n",
    "\n",
    "plt.hist([0.04, 0.3, 4, 5, 6, 0.02, 0.6], bins=2) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>426 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean radius mean texture mean perimeter mean area mean smoothness  \\\n",
       "266           1            1              1         1               1   \n",
       "442           1            1              1         1               1   \n",
       "339           0            0              0         0               1   \n",
       "400           0            1              0         1               0   \n",
       "397           1            1              1         1               1   \n",
       "..          ...          ...            ...       ...             ...   \n",
       "529           1            1              1         1               1   \n",
       "424           1            1              1         1               1   \n",
       "514           1            1              1         1               1   \n",
       "163           1            0              1         1               1   \n",
       "97            1            1              1         1               1   \n",
       "\n",
       "    mean compactness mean concavity mean concave points mean symmetry  \\\n",
       "266                1              1                   1             1   \n",
       "442                1              1                   1             1   \n",
       "339                1              0                   0             1   \n",
       "400                0              0                   0             0   \n",
       "397                1              1                   1             1   \n",
       "..               ...            ...                 ...           ...   \n",
       "529                1              1                   1             1   \n",
       "424                1              1                   1             0   \n",
       "514                1              1                   1             1   \n",
       "163                1              1                   1             1   \n",
       "97                 1              1                   1             1   \n",
       "\n",
       "    mean fractal dimension  ... worst radius worst texture worst perimeter  \\\n",
       "266                      1  ...            1             1               1   \n",
       "442                      1  ...            1             1               1   \n",
       "339                      1  ...            0             1               0   \n",
       "400                      1  ...            0             1               0   \n",
       "397                      1  ...            1             1               1   \n",
       "..                     ...  ...          ...           ...             ...   \n",
       "529                      1  ...            1             1               1   \n",
       "424                      1  ...            1             1               1   \n",
       "514                      1  ...            1             1               1   \n",
       "163                      1  ...            1             1               1   \n",
       "97                       1  ...            1             1               1   \n",
       "\n",
       "    worst area worst smoothness worst compactness worst concavity  \\\n",
       "266          1                1                 1               1   \n",
       "442          1                1                 1               1   \n",
       "339          0                0                 1               1   \n",
       "400          1                0                 0               0   \n",
       "397          1                1                 1               1   \n",
       "..         ...              ...               ...             ...   \n",
       "529          1                0                 1               1   \n",
       "424          1                1                 1               1   \n",
       "514          1                1                 1               1   \n",
       "163          1                1                 1               1   \n",
       "97           1                1                 1               1   \n",
       "\n",
       "    worst concave points worst symmetry worst fractal dimension  \n",
       "266                    1              1                       1  \n",
       "442                    1              1                       1  \n",
       "339                    0              1                       1  \n",
       "400                    0              1                       1  \n",
       "397                    1              1                       1  \n",
       "..                   ...            ...                     ...  \n",
       "529                    1              1                       1  \n",
       "424                    1              1                       1  \n",
       "514                    1              1                       1  \n",
       "163                    1              1                       1  \n",
       "97                     1              1                       1  \n",
       "\n",
       "[426 rows x 30 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformamos las caracteríticas de entrada a un valor binario\n",
    "X_train_bin = X_train.apply(pd.cut, bins=2, labels=[1, 0])\n",
    "X_test_bin = X_test.apply(pd.cut, bins=2, labels=[1, 0])\n",
    "\n",
    "X_train_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos el modelo MPNeuron\n",
    "mp_neuron = MPNeuron()\n",
    "\n",
    "# Encontramos el threshold óptimo\n",
    "mp_neuron.fit(X_train_bin.to_numpy(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Threshold óptimo seleccionado\n",
    "mp_neuron.threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos predicciones para ejemplos nuevos que no se encuentran en el conjunto de datos de entrenamiento\n",
    "Y_pred = mp_neuron.predict(X_test_bin.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False,  True, False, False, False,  True, False,\n",
       "       False,  True,  True, False,  True,  True,  True, False, False,\n",
       "        True,  True,  True,  True, False, False, False,  True,  True,\n",
       "       False, False,  True,  True, False,  True, False, False,  True,\n",
       "        True,  True, False, False, False,  True,  True, False,  True,\n",
       "       False,  True,  True,  True, False, False,  True, False,  True,\n",
       "        True,  True,  True, False,  True,  True, False, False, False,\n",
       "        True, False,  True, False,  True, False,  True, False,  True,\n",
       "        True,  True, False, False, False, False,  True,  True, False,\n",
       "       False, False,  True, False,  True, False,  True, False,  True,\n",
       "       False,  True,  True, False,  True, False, False,  True,  True,\n",
       "       False, False,  True, False, False, False, False,  True,  True,\n",
       "        True,  True,  True,  True,  True, False, False, False,  True,\n",
       "        True,  True, False, False,  True, False,  True,  True,  True,\n",
       "       False,  True,  True,  True, False,  True, False, False,  True,\n",
       "        True,  True,  True,  True,  True, False,  True, False])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8041958041958042"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculamos la exactitud de nuestra predicción\n",
    "accuracy_score(y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[45,  8],\n",
       "       [20, 70]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculamos la matriz de confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
